# CI/CD Azure DevOps deployment pipeline.
# The following variables can be optionally set for each pipeline run:
# - RUN_FLAG_TERRAFORM: Set to 1 to deploy shared infrastructure with Terraform.
#   By default this step only runs on the master branch.
# - RUN_FLAG_PROMOTE: Set to 1 to promote the Docker image to `latest` tag if
#   tests are successful. By default this is only done on the master branch.
# - RUN_SET_NAMEBASE: Set to a string to deploy to the given AKS namespace,
#   and not delete the namespace after the build. By default the build deploys to
#   the `master` AKS namespace if run on the master branch, and otherwise to a
#   temporary AKS namespace that is deleted at the end of the build.

jobs:

- job: build
  displayName: Build and unit tests
  pool: $(AGENT_POOL_NAME)
  steps:

  - bash: |
      set -eux  # fail on error
      # Only build first stage of Dockerfile (build and unit test)
      docker build --pull --target testrunner --build-arg VersionPrefix="$(SEMANTIC_VERSION)" -t contoso-build-$(Build.BuildId):test .
      docker run --rm -v $PWD/TestResults:/app/Contoso.UnitTests/TestResults contoso-build-$(Build.BuildId):test
    displayName: Docker build & test

  - task: PublishTestResults@2
    displayName: Publish test results
    condition: succeededOrFailed()
    inputs:
      testRunner: VSTest
      testResultsFiles: '**/*.trx'
      failTaskOnFailedTests: true
      testRunTitle: 'Unit Tests'

  # Publish the code coverage result (summary and web site)
  # The summary allows to view the coverage percentage in the summary tab
  # The web site allows to view which lines are covered directly in Azure Pipeline
  - task: PublishCodeCoverageResults@1
    displayName: 'Publish code coverage'
    inputs:
      codeCoverageTool: 'Cobertura'
      summaryFileLocation: '**/coverage.cobertura.xml'
      pathToSources: '$(Build.SourcesDirectory)/Src'
      failIfCoverageEmpty: true

  - task: AzureCLI@1
    displayName: Build runtime image
    inputs:
      azureSubscription: $(TERRAFORM_SERVICE_CONNECTION)
      scriptLocation: inlineScript
      inlineScript: |
        set -eux  # fail on error

        az configure --defaults acr="$ACR_NAME"
        az acr login

        # Build runtime Docker image
        # Reuses the cached build stage from the previous docker build task
        docker build --build-arg VersionPrefix="$(SEMANTIC_VERSION)" \
          -t "$ACR_NAME.azurecr.io/contoso:$(SEMANTIC_VERSION)" \
          .

        # Push Docker image to ACR
        docker push "$ACR_NAME.azurecr.io/contoso:$SEMANTIC_VERSION"


- job: Terraform_shared
  displayName: Deploy shared infrastructure
  # Avoid concurrent Terraform runs on PRs, which would result in failures due to exclusive lock on remote state file.
  condition: and(succeeded(), or(eq(variables['Build.SourceBranch'], 'refs/heads/master'), variables['RUN_FLAG_TERRAFORM']))
  variables:
    TERRAFORM_DIRECTORY: infrastructure/terraform-shared
  steps:

  - bash: |
      set -euo pipefail
      curl -sfu ":$(AGENT_POOL_MANAGEMENT_TOKEN)" '$(System.CollectionUri)_apis/distributedtask/pools?poolName=$(AGENT_POOL_NAME)&actionFilter=manage&api-version=5.1' \
        | jq -e '.count>0'
    displayName: Verify agent pool token

  - template: terraform-template.yml
    parameters:
      TerraformApply: true
      TerraformStateKey: cd
      TerraformVariables:
        ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)
        TF_VAR_appname: $(APP_NAME)
        TF_VAR_environment: cd
        TF_VAR_resource_group: $(RESOURCE_GROUP)
        TF_VAR_acr_name: $(ACR_NAME)
        TF_VAR_aks_version: $(AKS_VERSION)
        TF_VAR_aks_sp_client_id: $(AKS_SP_CLIENT_ID)
        TF_VAR_aks_sp_client_secret: $(AKS_SP_CLIENT_SECRET)
        TF_VAR_aks_sp_object_id: $(AKS_SP_OBJECT_ID)
        TF_VAR_app_sp_object_id: $(APP_SP_OBJECT_ID)
        TF_VAR_az_devops_agent_pool: $(AGENT_POOL_NAME)
        TF_VAR_az_devops_url: $(System.CollectionUri)
        TF_VAR_az_devops_pat: $(AGENT_POOL_MANAGEMENT_TOKEN)

- job: Terraform_shared_outputs
  displayName: Read shared infrastructure
  dependsOn:
  - Terraform_shared
  condition: |
    in(dependencies.Terraform_shared.result, 'Succeeded', 'SucceededWithIssues', 'Skipped')
  variables:
    TERRAFORM_DIRECTORY: infrastructure/terraform-shared
  steps:

  - template: terraform-template.yml
    parameters:
      TerraformStateKey: cd
      TerraformVariables:
        ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)

- job: Terraform
  displayName: Deploy infrastructure
  pool: $(AGENT_POOL_NAME)
  dependsOn:
  - Terraform_shared_outputs
  variables:
    KUBE_CONFIG_BASE64: $[ dependencies.Terraform_shared_outputs.outputs['Outputs.kube_config_base64'] ]
    COSMOSDB_ACCOUNT_NAME: $[ dependencies.Terraform_shared_outputs.outputs['Outputs.cosmosdb_account_name'] ]
    TERRAFORM_DIRECTORY: infrastructure/terraform
  steps:

  - bash: |
      set -eu  # fail on error

      AREA_NAME="build$(Build.BuildId)"
      if [ "$(Build.SourceBranch)" = "refs/heads/master" ]; then
        AREA_NAME="master"
      fi
      if [ "${RUN_SET_NAMEBASE:-}" != "" ]; then
        AREA_NAME="$RUN_SET_NAMEBASE"
      fi

      echo "Area name: $AREA_NAME"

      echo "##vso[task.setvariable variable=AREA_NAME;isOutput=true]$AREA_NAME"

    displayName: Define Deployment area
    name: area

  - template: terraform-template.yml
    parameters:
      TerraformDestroy: true
      TerraformApply: true
      TerraformStateKey: infra/$(area.AREA_NAME)
      TerraformVariables:
        ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)
        TF_VAR_appname: $(APP_NAME)
        TF_VAR_resource_group: $(RESOURCE_GROUP)
        TF_VAR_area_name: $(area.AREA_NAME)
        TF_VAR_cosmosdb_account_name: $(COSMOSDB_ACCOUNT_NAME)

- job: Terraform_app
  displayName: Deploy application
  pool: $(AGENT_POOL_NAME)
  dependsOn:
  - build
  - Terraform_shared_outputs
  - Terraform
  variables:
    KUBERNETES_NAMESPACE: $[ dependencies.Terraform.outputs['Outputs.kubernetes_namespace'] ]
    KUBE_CONFIG_BASE64: $[ dependencies.Terraform_shared_outputs.outputs['Outputs.kube_config_base64'] ]
    INSTRUMENTATION_KEY: $[ dependencies.Terraform_shared_outputs.outputs['Outputs.instrumentation_key'] ]
    COSMOS_DB_CONTAINER_ID: $[ dependencies.Terraform.outputs['Outputs.cosmosdb_container_id'] ]
    TERRAFORM_DIRECTORY: infrastructure/terraform-app
  steps:

  - template: terraform-template.yml
    parameters:
      TerraformApply: true
      TerraformStateKey: app/build-$(Build.BuildId)
      TerraformVariables:
        ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)
        TF_VAR_kubernetes_namespace: $(KUBERNETES_NAMESPACE)
        TF_VAR_release_name: $(HELM_RELEASE_NAME)
        TF_VAR_image_repository: $(ACR_NAME).azurecr.io/contoso
        TF_VAR_image_tag: $(SEMANTIC_VERSION)
        TF_VAR_client_id: $(APP_SP_CLIENT_ID)
        TF_VAR_tenant_id: $(ARM_TENANT_ID)
        TF_VAR_client_secret: $(APP_SP_CLIENT_SECRET)
        TF_VAR_instrumentation_key: $(INSTRUMENTATION_KEY)
        TF_VAR_cosmosdb_container_id: $(COSMOS_DB_CONTAINER_ID)

- job: Start_agents
  displayName: Start agents
  dependsOn:
  - Terraform_shared_outputs
  variables:
    AGENT_VMSS_NAME: $[ dependencies.Terraform_shared_outputs.outputs['Outputs.agent_vmss_name'] ]
    TERRAFORM_DIRECTORY: infrastructure/terraform-shared
  steps:

  - task: AzureCLI@1
    displayName: Start agents
    inputs:
      azureSubscription: $(TERRAFORM_SERVICE_CONNECTION)
      scriptLocation: inlineScript
      inlineScript: |
        set -eux  # fail on error
        # Trigger rerun of provisioning script if it has changed (based on CustomScript timestamp attribute)
        az vmss update-instances --instance-ids '*' --name $AGENT_VMSS_NAME --resource-group $RESOURCE_GROUP --no-wait
        az vmss scale --new-capacity 2 -o table --name $AGENT_VMSS_NAME --resource-group $RESOURCE_GROUP

- job: integration_tests
  displayName: Integration tests
  pool: $(AGENT_POOL_NAME)
  dependsOn:
  - Terraform
  - Terraform_shared_outputs
  - Terraform_app
  variables:
    KUBE_CONFIG_BASE64: $[ dependencies.Terraform_shared_outputs.outputs['Outputs.kube_config_base64'] ]
    KUBERNETES_NAMESPACE: $[ dependencies.Terraform.outputs['Outputs.kubernetes_namespace'] ]
  steps:

  - task: KubectlInstaller@0
    displayName: Install kubectl
    inputs:
      kubectlVersion: $(AKS_VERSION)

  - task: AlexandreGattiker.jmeter-tasks.custom-jmeter-installer-task.JMeterInstaller@0
    displayName: 'Install JMeter'
    inputs:
      jmeterVersion: $(JMETER_VERSION)
      plugins: jpgc-casutg,jpgc-dummy,jpgc-ffw,jpgc-fifo,jpgc-functions,jpgc-json,jpgc-perfmon,jpgc-prmctl,jpgc-tst,jmeter.backendlistener.azure

  - task: AlexandreGattiker.jmeter-tasks.custom-taurus-installer-task.TaurusInstaller@0
    displayName: 'Install Taurus'
    inputs:
      taurusVersion: 1.14.1
      pythonCommand: python3

  - bash: |
      set -eu  # fail on error
      base64 -d <<< $KUBE_CONFIG_BASE64 > kube_config
      echo "##vso[task.setvariable variable=KUBECONFIG]$PWD/kube_config"
    displayName: Save kubeconfig
    env:
      KUBE_CONFIG_BASE64: $(KUBE_CONFIG_BASE64)

  - bash: |
      set -eux  # fail on error
      read -d, firstNodeIP < <(kubectl -n "$KUBERNETES_NAMESPACE" get nodes -o jsonpath="{.items[0].status.addresses[?(@.type=='InternalIP')].address},")
      read -d, nodePort < <(kubectl -n "$KUBERNETES_NAMESPACE" get svc "$(HELM_RELEASE_NAME)" -o jsonpath="{.spec.ports[0].nodePort},")
      url="http://$firstNodeIP:$nodePort"
      echo "##vso[task.setvariable variable=SERVICE_URL]$url"
      echo "$url"
    displayName: Get Service URL

# FIXME: JUnit report generation fails if merging multiple scenarios in a single Task, so splitting across multiple Taurus runs.

  - task: AlexandreGattiker.jmeter-tasks.custom-taurus-runner-task.TaurusRunner@0
    displayName: 'Run Taurus'
    inputs:
      outputDir: 'taurus-output'
      reportName: 'Test Prometheus Endpoint'
      taurusConfig: |
        modules:
          jmeter:
            properties:
              jmeter.reportgenerator.overall_granularity: 5000
        execution:
        - scenario:
            requests:
            - url: $(SERVICE_URL)/metrics
              assert:
              - contains:
                - process_virtual_memory_bytes
                subject: body
          concurrency: 10
          ramp-up: 30s
          hold-for: 1m
          throughput: 20
        reporting:
        - module: junit-xml
          filename: taurus-output/TEST-Taurus.xml

  - task: AlexandreGattiker.jmeter-tasks.custom-taurus-runner-task.TaurusRunner@0
    displayName: 'Run Taurus'
    inputs:
      outputDir: 'taurus-output2'
      reportName: 'Test Sum Computation Endpoint'
      taurusConfig: |
        modules:
          jmeter:
            properties:
              jmeter.reportgenerator.overall_granularity: 5000
        execution:
        - scenario:
            requests:
            - url: $(SERVICE_URL)/sample/sumNumbersUpTo?value=100
              assert:
              - contains:
                - 5050
                subject: body
          hold-for: 20s
          throughput: 1
        #- scenario:
        #    requests:
        #    - url: $(SERVICE_URL)/sample/sumNumbersUpTo?value=-10
        #      assert:
        #      - contains:
        #        - 500
        #        subject: status-code
        #  iterations: 5
        reporting:
        - module: junit-xml
          filename: taurus-output2/TEST-Taurus.xml

  - task: PublishTestResults@2
    displayName: Publish test results
    inputs:
      testRunTitle: Integration tests
      failTaskOnFailedTests: true

- job: Cleanup
  displayName: Destroy infrastructure
  dependsOn:
  - integration_tests
  - Terraform_shared_outputs
  - Terraform
  pool: $(AGENT_POOL_NAME)
  variables:
    AREA_NAME: $[ dependencies.Terraform.outputs['area.AREA_NAME'] ]
    KUBE_CONFIG_BASE64: $[ dependencies.Terraform_shared_outputs.outputs['Outputs.kube_config_base64'] ]
    TERRAFORM_DIRECTORY: infrastructure/terraform-destroy
  # Destroy build-specific infrastructure unless either:
  # - deploying on master branch
  # - namespace was manually set with RUN_SET_NAMEBASE
  condition: and(always(), not(eq(variables['Build.SourceBranch'], 'refs/heads/master')), not(variables['RUN_SET_NAMEBASE']))
  steps:

  - template: terraform-template.yml
    parameters:
      TerraformDestroy: true
      TerraformStateKey: infra/$(AREA_NAME)
      TerraformVariables:
        ARM_CLIENT_SECRET: $(ARM_CLIENT_SECRET)

- job: Promote
  displayName: Promote latest image
  dependsOn: integration_tests
  condition: and(succeeded(), or(eq(variables['Build.SourceBranch'], 'refs/heads/master'), variables['RUN_FLAG_PROMOTE']))
  steps:

  - task: AzureCLI@1
    displayName: Tag Docker image as latest
    inputs:
      azureSubscription: $(TERRAFORM_SERVICE_CONNECTION)
      scriptLocation: inlineScript
      inlineScript: |
        set -eux  # fail on error
        az configure --defaults acr="$ACR_NAME"
        az acr login
        docker pull "$ACR_NAME.azurecr.io/contoso:$SEMANTIC_VERSION"
        docker tag \
          "$ACR_NAME.azurecr.io/contoso:$SEMANTIC_VERSION" \
          "$ACR_NAME.azurecr.io/contoso:latest"
        docker push "$ACR_NAME.azurecr.io/contoso:latest"
